{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet model for feature extraction\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download image from URL\n",
    "def download_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    return image\n",
    "\n",
    "# Function to extract features from an image\n",
    "def extract_features(image):\n",
    "    input_tensor = preprocess(image).unsqueeze(0)  # Create a mini-batch as expected by the model\n",
    "    with torch.no_grad():\n",
    "        features = model(input_tensor)\n",
    "    return features.numpy().flatten()  # Flatten to 1D array\n",
    "\n",
    "# Function to extract numeric value from string\n",
    "def extract_numeric(value):\n",
    "    match = re.search(r\"[\\d\\.]+\", value)\n",
    "    return float(match.group()) if match else None\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'D:\\React18\\newshop\\Feature-Extraction-from-Images-DEVMATES\\dataset\\sample_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoders\n",
    "entity_name_encoder = LabelEncoder()\n",
    "entity_value_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoders\n",
    "entity_name_encoder.fit(df['entity_name'].unique())\n",
    "entity_value_encoder.fit(df['entity_value'].unique())\n",
    "\n",
    "# Initialize a list to store results\n",
    "results = []\n",
    "\n",
    "# Iterate over the dataset\n",
    "for idx, row in df.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    entity_name = row['entity_name']\n",
    "    entity_value = row['entity_value']\n",
    "    \n",
    "    # Download and process image\n",
    "    image = download_image(image_url)\n",
    "    features = extract_features(image)\n",
    "    \n",
    "    # Encode entity names and values\n",
    "    encoded_entity_name = entity_name_encoder.transform([entity_name])[0]\n",
    "    encoded_entity_value = entity_value_encoder.transform([entity_value])[0]\n",
    "    \n",
    "    results.append({\n",
    "        'features': features.tolist(),\n",
    "        'encoded_entity_name': encoded_entity_name,\n",
    "        'encoded_entity_value': encoded_entity_value\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "features_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>encoded_entity_name</th>\n",
       "      <th>encoded_entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-3.2995729446411133, -4.209080696105957, -3.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-2.2146027088165283, -2.2432150840759277, -0....</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-6.495326042175293, -2.995445489883423, -1.69...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-3.9437735080718994, 1.7602643966674805, 0.82...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1.8861312866210938, -2.0388591289520264, -2....</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features  encoded_entity_name  \\\n",
       "0  [-3.2995729446411133, -4.209080696105957, -3.1...                    3   \n",
       "1  [-2.2146027088165283, -2.2432150840759277, -0....                    7   \n",
       "2  [-6.495326042175293, -2.995445489883423, -1.69...                    1   \n",
       "3  [-3.9437735080718994, 1.7602643966674805, 0.82...                    0   \n",
       "4  [-1.8861312866210938, -2.0388591289520264, -2....                    3   \n",
       "\n",
       "   encoded_entity_value  \n",
       "0                     7  \n",
       "1                    76  \n",
       "2                    12  \n",
       "3                    40  \n",
       "4                    10  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['encoded_entity_name', 'encoded_entity_value', 'feature_0', 'feature_1',\n",
      "       'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6',\n",
      "       'feature_7',\n",
      "       ...\n",
      "       'feature_990', 'feature_991', 'feature_992', 'feature_993',\n",
      "       'feature_994', 'feature_995', 'feature_996', 'feature_997',\n",
      "       'feature_998', 'feature_999'],\n",
      "      dtype='object', length=1002)\n",
      "   encoded_entity_name  encoded_entity_value  feature_0  feature_1  feature_2  \\\n",
      "0                    3                     7  -3.299573  -4.209081  -3.180969   \n",
      "1                    7                    76  -2.214603  -2.243215  -0.999183   \n",
      "2                    1                    12  -6.495326  -2.995445  -1.694585   \n",
      "3                    0                    40  -3.943774   1.760264   0.826122   \n",
      "4                    3                    10  -1.886131  -2.038859  -2.236290   \n",
      "\n",
      "   feature_3  feature_4  feature_5  feature_6  feature_7  ...  feature_990  \\\n",
      "0  -0.735489   0.982856  -3.855928  -6.124228  -2.362949  ...    -2.388696   \n",
      "1  -0.998531  -0.802855  -0.843652  -2.884283  -0.114411  ...    -0.262714   \n",
      "2  -1.302688  -0.531743  -1.468706  -4.796603  -1.348032  ...    -1.093952   \n",
      "3   1.107996   0.007000  -1.325379  -1.086260  -1.358907  ...    -0.749811   \n",
      "4  -0.052591   1.068134   2.215033  -2.115244  -2.361414  ...    -2.190348   \n",
      "\n",
      "   feature_991  feature_992  feature_993  feature_994  feature_995  \\\n",
      "0    -3.696410    -4.502243    -3.338748    -4.913984    -5.171934   \n",
      "1    -2.034765    -4.008804    -3.590989    -3.246768    -2.582219   \n",
      "2    -3.690505    -4.137578    -3.121323    -1.220875    -2.373565   \n",
      "3    -2.013833    -2.405521    -2.928203     0.183115    -2.732264   \n",
      "4    -4.783791    -5.093812    -3.842153    -4.416555    -1.162961   \n",
      "\n",
      "   feature_996  feature_997  feature_998  feature_999  \n",
      "0     0.420845    -5.645026    -1.203192     2.595617  \n",
      "1    -1.996611    -2.494826     0.456023    -1.245745  \n",
      "2    -0.618034    -3.169698    -1.611693     3.783908  \n",
      "3    -1.353597    -2.588346     0.835229     5.307116  \n",
      "4    -1.455895    -3.952430     1.734921     2.158779  \n",
      "\n",
      "[5 rows x 1002 columns]\n"
     ]
    }
   ],
   "source": [
    "# Expand features into separate columns\n",
    "features_expanded = pd.DataFrame(features_df['features'].tolist(), columns=[f'feature_{i}' for i in range(len(features_df['features'][0]))])\n",
    "features_df = pd.concat([features_df.drop(columns=['features']), features_expanded], axis=1)\n",
    "\n",
    "# Print column names and first few rows to check if 'features' exists\n",
    "print(features_df.columns)\n",
    "print(features_df.head())\n",
    "\n",
    "# Prepare data for modeling\n",
    "X = features_df.drop(columns=['encoded_entity_value'])\n",
    "y = features_df['encoded_entity_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_entity_name</th>\n",
       "      <th>encoded_entity_value</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_990</th>\n",
       "      <th>feature_991</th>\n",
       "      <th>feature_992</th>\n",
       "      <th>feature_993</th>\n",
       "      <th>feature_994</th>\n",
       "      <th>feature_995</th>\n",
       "      <th>feature_996</th>\n",
       "      <th>feature_997</th>\n",
       "      <th>feature_998</th>\n",
       "      <th>feature_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-3.299573</td>\n",
       "      <td>-4.209081</td>\n",
       "      <td>-3.180969</td>\n",
       "      <td>-0.735489</td>\n",
       "      <td>0.982856</td>\n",
       "      <td>-3.855928</td>\n",
       "      <td>-6.124228</td>\n",
       "      <td>-2.362949</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.388696</td>\n",
       "      <td>-3.696410</td>\n",
       "      <td>-4.502243</td>\n",
       "      <td>-3.338748</td>\n",
       "      <td>-4.913984</td>\n",
       "      <td>-5.171934</td>\n",
       "      <td>0.420845</td>\n",
       "      <td>-5.645026</td>\n",
       "      <td>-1.203192</td>\n",
       "      <td>2.595617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>-2.214603</td>\n",
       "      <td>-2.243215</td>\n",
       "      <td>-0.999183</td>\n",
       "      <td>-0.998531</td>\n",
       "      <td>-0.802855</td>\n",
       "      <td>-0.843652</td>\n",
       "      <td>-2.884283</td>\n",
       "      <td>-0.114411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262714</td>\n",
       "      <td>-2.034765</td>\n",
       "      <td>-4.008804</td>\n",
       "      <td>-3.590989</td>\n",
       "      <td>-3.246768</td>\n",
       "      <td>-2.582219</td>\n",
       "      <td>-1.996611</td>\n",
       "      <td>-2.494826</td>\n",
       "      <td>0.456023</td>\n",
       "      <td>-1.245745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>-6.495326</td>\n",
       "      <td>-2.995445</td>\n",
       "      <td>-1.694585</td>\n",
       "      <td>-1.302688</td>\n",
       "      <td>-0.531743</td>\n",
       "      <td>-1.468706</td>\n",
       "      <td>-4.796603</td>\n",
       "      <td>-1.348032</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.093952</td>\n",
       "      <td>-3.690505</td>\n",
       "      <td>-4.137578</td>\n",
       "      <td>-3.121323</td>\n",
       "      <td>-1.220875</td>\n",
       "      <td>-2.373565</td>\n",
       "      <td>-0.618034</td>\n",
       "      <td>-3.169698</td>\n",
       "      <td>-1.611693</td>\n",
       "      <td>3.783908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>-3.943774</td>\n",
       "      <td>1.760264</td>\n",
       "      <td>0.826122</td>\n",
       "      <td>1.107996</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>-1.325379</td>\n",
       "      <td>-1.086260</td>\n",
       "      <td>-1.358907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.749811</td>\n",
       "      <td>-2.013833</td>\n",
       "      <td>-2.405521</td>\n",
       "      <td>-2.928203</td>\n",
       "      <td>0.183115</td>\n",
       "      <td>-2.732264</td>\n",
       "      <td>-1.353597</td>\n",
       "      <td>-2.588346</td>\n",
       "      <td>0.835229</td>\n",
       "      <td>5.307116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.886131</td>\n",
       "      <td>-2.038859</td>\n",
       "      <td>-2.236290</td>\n",
       "      <td>-0.052591</td>\n",
       "      <td>1.068134</td>\n",
       "      <td>2.215033</td>\n",
       "      <td>-2.115244</td>\n",
       "      <td>-2.361414</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.190348</td>\n",
       "      <td>-4.783791</td>\n",
       "      <td>-5.093812</td>\n",
       "      <td>-3.842153</td>\n",
       "      <td>-4.416555</td>\n",
       "      <td>-1.162961</td>\n",
       "      <td>-1.455895</td>\n",
       "      <td>-3.952430</td>\n",
       "      <td>1.734921</td>\n",
       "      <td>2.158779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_entity_name  encoded_entity_value  feature_0  feature_1  feature_2  \\\n",
       "0                    3                     7  -3.299573  -4.209081  -3.180969   \n",
       "1                    7                    76  -2.214603  -2.243215  -0.999183   \n",
       "2                    1                    12  -6.495326  -2.995445  -1.694585   \n",
       "3                    0                    40  -3.943774   1.760264   0.826122   \n",
       "4                    3                    10  -1.886131  -2.038859  -2.236290   \n",
       "\n",
       "   feature_3  feature_4  feature_5  feature_6  feature_7  ...  feature_990  \\\n",
       "0  -0.735489   0.982856  -3.855928  -6.124228  -2.362949  ...    -2.388696   \n",
       "1  -0.998531  -0.802855  -0.843652  -2.884283  -0.114411  ...    -0.262714   \n",
       "2  -1.302688  -0.531743  -1.468706  -4.796603  -1.348032  ...    -1.093952   \n",
       "3   1.107996   0.007000  -1.325379  -1.086260  -1.358907  ...    -0.749811   \n",
       "4  -0.052591   1.068134   2.215033  -2.115244  -2.361414  ...    -2.190348   \n",
       "\n",
       "   feature_991  feature_992  feature_993  feature_994  feature_995  \\\n",
       "0    -3.696410    -4.502243    -3.338748    -4.913984    -5.171934   \n",
       "1    -2.034765    -4.008804    -3.590989    -3.246768    -2.582219   \n",
       "2    -3.690505    -4.137578    -3.121323    -1.220875    -2.373565   \n",
       "3    -2.013833    -2.405521    -2.928203     0.183115    -2.732264   \n",
       "4    -4.783791    -5.093812    -3.842153    -4.416555    -1.162961   \n",
       "\n",
       "   feature_996  feature_997  feature_998  feature_999  \n",
       "0     0.420845    -5.645026    -1.203192     2.595617  \n",
       "1    -1.996611    -2.494826     0.456023    -1.245745  \n",
       "2    -0.618034    -3.169698    -1.611693     3.783908  \n",
       "3    -1.353597    -2.588346     0.835229     5.307116  \n",
       "4    -1.455895    -3.952430     1.734921     2.158779  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # Initialize MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # Select all feature columns for scaling\n",
    "# feature_columns = [col for col in features_df.columns if col.startswith('feature_')]\n",
    "\n",
    "# # Fit and transform the selected feature columns\n",
    "# features_df[feature_columns] = scaler.fit_transform(features_df[feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Model: SVM\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.0500\n",
      "Precision: 0.0250\n",
      "Recall: 0.0500\n",
      "F1 Score: 0.0333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoost\n",
      "Accuracy: 0.0500\n",
      "Precision: 0.0028\n",
      "Recall: 0.0500\n",
      "F1 Score: 0.0053\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Iterate over models, train, and evaluate\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print()  # Print a newline for better readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test= pd.read_csv(r\"D:\\React18\\newshop\\Feature-Extraction-from-Images-DEVMATES\\dataset\\test_data.csv\")\n",
    "X_test = X_test.drop(columns=['index','decoded_entity','decoded_entity_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encoded_entity_name', 'feature_0', 'feature_1', 'feature_2',\n",
       "       'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7',\n",
       "       'feature_8',\n",
       "       ...\n",
       "       'feature_990', 'feature_991', 'feature_992', 'feature_993',\n",
       "       'feature_994', 'feature_995', 'feature_996', 'feature_997',\n",
       "       'feature_998', 'feature_999'],\n",
       "      dtype='object', length=1001)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()\n",
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['encoded_entity_name', 'feature_0', 'feature_1', 'feature_2',\n",
       "       'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7',\n",
       "       'feature_8',\n",
       "       ...\n",
       "       'feature_990', 'feature_991', 'feature_992', 'feature_993',\n",
       "       'feature_994', 'feature_995', 'feature_996', 'feature_997',\n",
       "       'feature_998', 'feature_999'],\n",
       "      dtype='object', length=1001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted entity values saved to 'predicted_entity_values.csv'.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Entity to unit mapping\n",
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n",
    "                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
    "}\n",
    "\n",
    "# Allowed units set\n",
    "allowed_units = {unit for entity in entity_unit_map for unit in entity_unit_map[entity]}\n",
    "\n",
    "# Function to format prediction with a unit\n",
    "def format_prediction(prediction, unit):\n",
    "    \"\"\"Format prediction as 'x unit'.\"\"\"\n",
    "    return f\"{prediction:.2f} {unit}\"\n",
    "\n",
    "# Function to assign a random unit from the allowed units of a given entity\n",
    "def assign_unit(entity):\n",
    "    \"\"\"Assign a unit based on the entity from the entity_unit_map.\"\"\"\n",
    "    if entity in entity_unit_map:\n",
    "        return random.choice(list(entity_unit_map[entity]))  # Choose a random unit from valid ones for the entity\n",
    "    else:\n",
    "        return random.choice(list(allowed_units))  # Fall back to any allowed unit if entity is not found\n",
    "\n",
    "# Example entities list based on your dataset\n",
    "entities = ['width', 'height', 'item_weight', 'voltage', 'wattage', 'item_volume']  # Replace with actual entity predictions\n",
    "\n",
    "# List to store the formatted predictions for saving to CSV\n",
    "formatted_predictions = []\n",
    "\n",
    "# Iterate over the predictions and format them accordingly\n",
    "for idx, pred in enumerate(y_pred):\n",
    "    entity = entities[idx % len(entities)]  # Assign an entity in a cycle (this is an example)\n",
    "    unit = assign_unit(entity)  # Get the correct unit for the entity\n",
    "    formatted_pred = format_prediction(pred, unit)  # Format the prediction with a unit\n",
    "    \n",
    "    # Append the result in a dictionary format for easy conversion to a DataFrame later\n",
    "    formatted_predictions.append({\"index\": idx, \"entity\": entity, \"prediction\": formatted_pred})\n",
    "\n",
    "# Convert the list of formatted predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(formatted_predictions)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predictions_df.to_csv(\"predicted_entity_values.csv\", index=False)\n",
    "\n",
    "print(\"Predicted entity values saved to 'predicted_entity_values.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
